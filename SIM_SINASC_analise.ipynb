{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando Pacotes e Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extraindo Bases de dados do ZIP - 2018 até 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_arquivo_zip = ''\n",
    "#Abre o arquivo ZIP\n",
    "with zipfile.ZipFile(nome_arquivo_zip, 'r') as zip_ref:\n",
    "    #Obtem uma lista de nomes de arquivos dentro do ZIP\n",
    "    nomes_arquivos = zip_ref.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ETLSINASC.DNRES_AC_2018_t.csv', 'ETLSINASC.DNRES_AC_2019_t.csv', 'ETLSINASC.DNRES_AL_2018_t.csv', 'ETLSINASC.DNRES_AL_2019_t.csv', 'ETLSINASC.DNRES_AM_2018_t.csv', 'ETLSINASC.DNRES_AM_2019_t.csv', 'ETLSINASC.DNRES_AP_2018_t.csv', 'ETLSINASC.DNRES_AP_2019_t.csv', 'ETLSINASC.DNRES_BA_2018_t.csv', 'ETLSINASC.DNRES_BA_2019_t.csv', 'ETLSINASC.DNRES_CE_2018_t.csv', 'ETLSINASC.DNRES_CE_2019_t.csv', 'ETLSINASC.DNRES_DF_2018_t.csv', 'ETLSINASC.DNRES_DF_2019_t.csv', 'ETLSINASC.DNRES_ES_2018_t.csv', 'ETLSINASC.DNRES_ES_2019_t.csv', 'ETLSINASC.DNRES_GO_2018_t.csv', 'ETLSINASC.DNRES_GO_2019_t.csv', 'ETLSINASC.DNRES_MA_2018_t.csv', 'ETLSINASC.DNRES_MA_2019_t.csv', 'ETLSINASC.DNRES_MG_2018_t.csv', 'ETLSINASC.DNRES_MG_2019_t.csv', 'ETLSINASC.DNRES_MS_2018_t.csv', 'ETLSINASC.DNRES_MS_2019_t.csv', 'ETLSINASC.DNRES_MT_2018_t.csv', 'ETLSINASC.DNRES_MT_2019_t.csv', 'ETLSINASC.DNRES_PA_2018_t.csv', 'ETLSINASC.DNRES_PA_2019_t.csv', 'ETLSINASC.DNRES_PB_2018_t.csv', 'ETLSINASC.DNRES_PB_2019_t.csv', 'ETLSINASC.DNRES_PE_2018_t.csv', 'ETLSINASC.DNRES_PE_2019_t.csv', 'ETLSINASC.DNRES_PI_2018_t.csv', 'ETLSINASC.DNRES_PI_2019_t.csv', 'ETLSINASC.DNRES_PR_2018_t.csv', 'ETLSINASC.DNRES_PR_2019_t.csv', 'ETLSINASC.DNRES_RJ_2018_t.csv', 'ETLSINASC.DNRES_RJ_2019_t.csv', 'ETLSINASC.DNRES_RN_2018_t.csv', 'ETLSINASC.DNRES_RN_2019_t.csv', 'ETLSINASC.DNRES_RO_2018_t.csv', 'ETLSINASC.DNRES_RO_2019_t.csv', 'ETLSINASC.DNRES_RR_2018_t.csv', 'ETLSINASC.DNRES_RR_2019_t.csv', 'ETLSINASC.DNRES_RS_2018_t.csv', 'ETLSINASC.DNRES_RS_2019_t.csv', 'ETLSINASC.DNRES_SC_2018_t.csv', 'ETLSINASC.DNRES_SC_2019_t.csv', 'ETLSINASC.DNRES_SE_2018_t.csv', 'ETLSINASC.DNRES_SE_2019_t.csv', 'ETLSINASC.DNRES_SP_2018_t.csv', 'ETLSINASC.DNRES_SP_2019_t.csv', 'ETLSINASC.DNRES_TO_2018_t.csv', 'ETLSINASC.DNRES_TO_2019_t.csv', 'ETLSINASC.DNRES_AC_2020_t.csv', 'ETLSINASC.DNRES_AL_2020_t.csv', 'ETLSINASC.DNRES_AM_2020_t.csv', 'ETLSINASC.DNRES_AP_2020_t.csv', 'ETLSINASC.DNRES_BA_2020_t.csv', 'ETLSINASC.DNRES_CE_2020_t.csv', 'ETLSINASC.DNRES_DF_2020_t.csv', 'ETLSINASC.DNRES_ES_2020_t.csv', 'ETLSINASC.DNRES_GO_2020_t.csv', 'ETLSINASC.DNRES_MA_2020_t.csv', 'ETLSINASC.DNRES_MG_2020_t.csv', 'ETLSINASC.DNRES_MS_2020_t.csv', 'ETLSINASC.DNRES_MT_2020_t.csv', 'ETLSINASC.DNRES_PA_2020_t.csv', 'ETLSINASC.DNRES_PB_2020_t.csv', 'ETLSINASC.DNRES_PE_2020_t.csv', 'ETLSINASC.DNRES_PI_2020_t.csv', 'ETLSINASC.DNRES_PR_2020_t.csv', 'ETLSINASC.DNRES_RJ_2020_t.csv', 'ETLSINASC.DNRES_RN_2020_t.csv', 'ETLSINASC.DNRES_RO_2020_t.csv', 'ETLSINASC.DNRES_RR_2020_t.csv', 'ETLSINASC.DNRES_RS_2020_t.csv', 'ETLSINASC.DNRES_SC_2020_t.csv', 'ETLSINASC.DNRES_SE_2020_t.csv', 'ETLSINASC.DNRES_SP_2020_t.csv', 'ETLSINASC.DNRES_TO_2020_t.csv', 'ETLSINASC.DNRES_AC_2021_t.csv', 'ETLSINASC.DNRES_AL_2021_t.csv', 'ETLSINASC.DNRES_AM_2021_t.csv', 'ETLSINASC.DNRES_AP_2021_t.csv', 'ETLSINASC.DNRES_BA_2021_t.csv', 'ETLSINASC.DNRES_CE_2021_t.csv', 'ETLSINASC.DNRES_DF_2021_t.csv', 'ETLSINASC.DNRES_ES_2021_t.csv', 'ETLSINASC.DNRES_GO_2021_t.csv', 'ETLSINASC.DNRES_MA_2021_t.csv', 'ETLSINASC.DNRES_MG_2021_t.csv', 'ETLSINASC.DNRES_MS_2021_t.csv', 'ETLSINASC.DNRES_MT_2021_t.csv', 'ETLSINASC.DNRES_PA_2021_t.csv', 'ETLSINASC.DNRES_PB_2021_t.csv', 'ETLSINASC.DNRES_PE_2021_t.csv', 'ETLSINASC.DNRES_PI_2021_t.csv', 'ETLSINASC.DNRES_PR_2021_t.csv', 'ETLSINASC.DNRES_RJ_2021_t.csv', 'ETLSINASC.DNRES_RN_2021_t.csv', 'ETLSINASC.DNRES_RO_2021_t.csv', 'ETLSINASC.DNRES_RR_2021_t.csv', 'ETLSINASC.DNRES_RS_2021_t.csv', 'ETLSINASC.DNRES_SC_2021_t.csv', 'ETLSINASC.DNRES_SE_2021_t.csv', 'ETLSINASC.DNRES_SP_2021_t.csv', 'ETLSINASC.DNRES_TO_2021_t.csv']\n"
     ]
    }
   ],
   "source": [
    "lista_anos = [nome for nome in nomes_arquivos if any(ano in nome for ano in [\"2018\", \"2019\", \"2020\", \"2021\"])]\n",
    "print(lista_anos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diretorio_destino' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Certifica-se de que o diretório de destino existe, ou cria-o se necessário\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[43mdiretorio_destino\u001b[49m):\n\u001b[0;32m      3\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(diretorio_destino)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extrai apenas os arquivos que atendem aos anos da lista_anos\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diretorio_destino' is not defined"
     ]
    }
   ],
   "source": [
    "caminho_arquivo_zip = ''\n",
    "diretorio_destino = ''\n",
    "\n",
    "# Certifica-se de que o diretório de destino existe, ou cria-o se necessário\n",
    "if not os.path.exists(diretorio_destino):\n",
    "    os.makedirs(diretorio_destino)\n",
    "\n",
    "# Extrai apenas os arquivos que atendem aos anos da lista_anos\n",
    "with zipfile.ZipFile(caminho_arquivo_zip, 'r') as zip_ref:\n",
    "    for info_arquivo in zip_ref.infolist():\n",
    "        nome_arquivo = info_arquivo.filename\n",
    "        if any(ano in nome_arquivo for ano in lista_anos):\n",
    "            zip_ref.extract(info_arquivo, diretorio_destino)\n",
    "\n",
    "print(f'Arquivos zip extraídos em: {diretorio_destino}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Carregando Bases de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\E'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\E'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\E'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\E'\n",
      "C:\\Users\\Elke\\AppData\\Local\\Temp\\ipykernel_1824\\2431206643.py:1: SyntaxWarning: invalid escape sequence '\\E'\n",
      "  df_SIM = pd.read_csv('SIM\\ETLSIM.DORES_AC_2018_t.csv')\n",
      "C:\\Users\\Elke\\AppData\\Local\\Temp\\ipykernel_1824\\2431206643.py:2: SyntaxWarning: invalid escape sequence '\\E'\n",
      "  df_SINASC = pd.read_csv('SINASC\\ETLSINASC.DNRES_AC_2018_t.csv')\n",
      "C:\\Users\\Elke\\AppData\\Local\\Temp\\ipykernel_1824\\2431206643.py:2: DtypeWarning: Columns (117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_SINASC = pd.read_csv('SINASC\\ETLSINASC.DNRES_AC_2018_t.csv')\n"
     ]
    }
   ],
   "source": [
    "df_SIM = pd.read_csv('SIM\\ETLSIM.DORES_AC_2018_t.csv')  \n",
    "df_SINASC = pd.read_csv('SINASC\\ETLSINASC.DNRES_AC_2018_t.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análise Preliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos da coluna 'ano_obito':\n",
      "[2018]\n",
      "Valores únicos da coluna 'res_SIGLA_UF':\n",
      "['AC']\n"
     ]
    }
   ],
   "source": [
    "# Lista de colunas desejadas\n",
    "colunas_desejadas = ['ano_obito', 'res_SIGLA_UF']\n",
    "\n",
    "# Itera sobre as colunas e imprime os valores únicos\n",
    "for coluna in colunas_desejadas:\n",
    "    valores_unicos = df_SIM[coluna].unique()\n",
    "    print(f\"Valores únicos da coluna '{coluna}':\")\n",
    "    print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos da coluna 'ano_nasc':\n",
      "[2018]\n",
      "Valores únicos da coluna 'res_SIGLA_UF':\n",
      "['AC']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "colunas_desejadas = ['ano_nasc', 'res_SIGLA_UF']\n",
    "\n",
    "for coluna in colunas_desejadas:\n",
    "    valores_unicos = df_SINASC[coluna].unique()\n",
    "    print(f\"Valores únicos da coluna '{coluna}':\")\n",
    "    print(valores_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ano que está nomeando os arquivos na SIM refere-se ao ano de óbito e na SINASC ao ano de nascimento.\n",
    "Já a UF que aparece nomeando os arquivos diz respeito a unidade da federação de residência da pessoa que foi à óbito na SIM e a residência da pessoa nascida na SINASC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas em comum: {'res_NOME_UF', 'IDADEMAE', 'res_coordenadas', 'res_FRONTEIRA', 'PARTO', 'res_RSAUDCOD', 'def_gestacao', 'SEMAGESTAC', 'res_SIGLA_UF', 'CODESTAB', 'def_parto', 'res_MSAUDCOD', 'data_nasc', 'res_AMAZONIA', 'CONTADOR', 'def_est_civil', 'DTRECORIGA', 'dia_semana_nasc', 'RACACOR', 'CODMUNRES', 'PESO', 'def_gravidez', 'DIFDATA', 'res_LATITUDE', 'DTNASC', 'def_raca_cor', 'res_CAPITAL', 'ORIGEM', 'SEXO', 'GESTACAO', 'res_CODIGO_UF', 'ESCMAEAGR1', 'CODMUNNATU', 'ESCMAE2010', 'SERIESCMAE', 'def_sexo', 'res_CSAUDCOD', 'ano_nasc', 'NUMEROLOTE', 'DTCADASTRO', 'res_REGIAO', 'ESCMAE', 'res_MUNNOME', 'res_ALTITUDE', 'GRAVIDEZ', 'VERSAOSIST', 'res_AREA', 'QTDFILMORT', 'res_MUNNOMEX', 'QTDFILVIVO', 'res_codigo_adotado', 'res_LONGITUDE', 'DTRECEBIM', 'def_escol_mae'}\n"
     ]
    }
   ],
   "source": [
    "# Obtem os nomes das colunas de ambos os DataFrames\n",
    "colunas_df1 = set(df_SIM.columns)\n",
    "colunas_df2 = set(df_SINASC.columns)\n",
    "\n",
    "# Encontra a interseção (colunas comuns) entre os dois conjuntos\n",
    "colunas_comuns = colunas_df1.intersection(colunas_df2)\n",
    "\n",
    "print(\"Colunas em comum:\", colunas_comuns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As colunas em comum podem ser usadas como chave pra juntar posteriormente as bases de daodos. No entanto, é preciso avaliar todas as colunas pois pode aparecer inconsistências em colunas comuns. Por exemplo, terem significados ou tipos diferentes, mesmo com os mesmos nomes.\n",
    "Além disso, pode-se criar colunas que podem fazer parte da chave. Por exemplo, Natural na SIM contém a informação de nasc_SIGLA_UF da SINASC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A coluna DTRECORIGA tem tipos diferentes: float64 em df1 e int64 em df2.\n",
      "A coluna DTNASC tem tipos diferentes: int64 em df1 e float64 em df2.\n",
      "A coluna ano_nasc tem tipos diferentes: int64 em df1 e float64 em df2.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se as colunas comuns têm o mesmo tipo de dados\n",
    "for coluna in colunas_comuns:\n",
    "    tipo_df1 = df_SINASC[coluna].dtype\n",
    "    tipo_df2 = df_SIM[coluna].dtype\n",
    "\n",
    "    if tipo_df1 != tipo_df2:\n",
    "        print(f\"A coluna {coluna} tem tipos diferentes: {tipo_df1} em df1 e {tipo_df2} em df2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amb_virt_prematuridade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
